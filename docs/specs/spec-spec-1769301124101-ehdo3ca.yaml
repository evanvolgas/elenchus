id: spec-1769301124101-ehdo3ca
epicId: epic-1769300705114-lnth312
sessionId: session-1769300836267-vm0vs1r
version: 1
problem: Enable Elenchus to properly detect and analyze Python, TypeScript, PHP,
  and Go projects. Currently Python detection fails for pyproject.toml-based
  projects (especially uv-managed). This blocks accurate codebase analysis
  needed for spec generation.
userPersona: Both Elenchus users analyzing their own codebases and AI agents
  using Elenchus to understand project structure before generating specs.
successMetrics:
  - name: "Criterion: [ ] `hasTests: true` when `tes..."
    description: "[ ] `hasTests: true` when `tests/test_*.py` files exist"
    target: Pass
    measurement: Test or manual verification
    priority: secondary
  - name: "Criterion: [ ] `hasLinting: true` when `[..."
    description: "[ ] `hasLinting: true` when `[tool.ruff]` or similar configured"
    target: Pass
    measurement: Test or manual verification
    priority: secondary
  - name: "Criterion: [ ] `dependencies` populated f..."
    description: "[ ] `dependencies` populated from pyproject.toml"
    target: Pass
    measurement: Test or manual verification
    priority: secondary
outOfScope:
  - Deep dependency resolution (just detect dependencies from manifest files).
    Full AST parsing of source code. Support for less common package managers.
    Migration tools.
codebaseContext:
  analyzedAt: 2026-01-25T00:17:22.926Z
  rootPath: .
  analysisDepth: deep
  maturity: established
  architecture: hybrid
  primaryLanguage: Python
  frameworks: []
  conventions:
    - type: file-structure
      pattern: src/ directory for source code
      examples:
        - src/index.ts
        - src/components/
      confidence: 80
    - type: testing
      pattern: tests/ directory for tests
      examples:
        - tests/component.test.ts
      confidence: 80
  suggestedPatterns: []
  dependencies: []
  testCoverage:
    overallPercentage: 0
    hasTests: false
    criticalPathsCovered: false
  hasTypeScript: false
  hasLinting: false
  hasCICD: true
  riskAreas:
    - area: Type Safety
      level: medium
      reason: No TypeScript configuration found. Type errors may go undetected.
      mitigations:
        - Consider adding TypeScript
        - Use JSDoc for type hints
  relevantFiles:
    - path: .env.example
      relevance: 80
      reason: Configuration file
  contextFiles:
    claudeMd: |
      # Engram Agent Guide

      **What is Engram**: Memory you can trust. A memory system for AI applications that preserves ground truth, tracks confidence, and prevents hallucinations.

      **Status**: Beta. 800+ tests. Core APIs, REST endpoints, and workflows fully implemented.

      **Your Role**: Python backend engineer building a memory layer for AI agents. You write production-grade code with comprehensive tests.

      **Design Philosophy**: Ground truth preservation, auditable confidence, deferred consolidation.

      ---

      ## Boundaries

      ### Always Do (No Permission Needed)

      - Write complete, production-grade code (no TODOs, no placeholders)
      - Add tests for all new features (test both success and error cases)
      - Use type hints (mypy strict mode)
      - Follow async/await patterns for all database operations
      - Update README.md when adding user-facing features
      - Add docstrings to public functions
      - **Use Pydantic for ALL data models** — no dataclasses, no TypedDict, no NamedTuple
      - **Use Pydantic AI for ALL LLM interactions** — structured outputs, type-safe responses

      ### Ask First

      - Modifying database models (affects migrations)
      - Changing API contracts (breaking for consumers)
      - Adding new dependencies to pyproject.toml
      - Deleting existing endpoints or models
      - Refactoring core services (storage, extraction, consolidation)

      ### Never Do

      **GitHub Issues**:
      - NEVER close an issue unless ALL acceptance criteria are met
      - If an issue has checkboxes, ALL boxes must be checked before closing
      - If you can't complete all criteria, leave the issue open and comment on what remains

      **Git**:
      - NEVER commit directly to main - always use a feature branch and PR
      - NEVER push directly to main - all changes must go through pull requests
      - NEVER force push to shared branches
      - Do NOT include "Co-Authored-By: Claude" or the "Generated with Claude Code" footer

      **Security**:
      - NEVER commit credentials, API keys, tokens, or passwords
      - Use environment variables (.env is in .gitignore)
      - Pre-commit check: `grep -r "sk-\|sk-ant-\|AIza" src/ tests/ && echo "SECRETS FOUND" || echo "OK"`

      **Code Quality**:
      - Skip tests to make builds pass
      - Disable type checking or linting
      - Leave TODO comments in production code
      - Delete failing tests instead of fixing them

      ---

      ## Commands

      ```bash
      # Setup
      uv sync --extra dev

      # Run tests
      uv run pytest tests/ -v --no-cov

      # Code quality
      uv run ruff check src/engram/
      uv run ruff format src/engram/
      uv run mypy src/engram/

      # Pre-commit
      uv run pre-commit install
      uv run pre-commit run --all-files

      # Start REST API server
      uv run uvicorn engram.api.app:app --port 8000
      ```

      ---

      ## REST API

      All endpoints are prefixed with `/api/v1`. Key endpoints:

      | Endpoint | Method | Description |
      |----------|--------|-------------|
      | `/encode` | POST | Store episode + extract structured data |
      | `/encode/batch` | POST | Bulk import (up to 100 items) |
      | `/recall` | POST | Semantic search across memory types |
      | `/memories/{id}` | GET | Get specific memory |
      | `/memories/{id}` | DELETE | Delete memory (with cascade options) |
      | `/memories/{id}/verify` | GET | Trace memory to source |
      | `/workflows/consolidate` | POST | Episodes → Semantic memories |
      | `/workflows/promote` | POST | Semantic → Procedural |

      See `docs/api.md` for full documentation.

      ---

      ## Key Concepts

      ### Memory Types (5)

      | Type | Purpose | Confidence |
      |------|---------|------------|
      | Working | Current session context (in-memory, not persisted) | N/A |
      | Episode | Immutable ground truth (raw interactions) | N/A (verbatim) |
      | StructuredMemory | Per-episode LLM extraction (entities, summary, negations) | 0.8-0.9 |
      | SemanticMemory | Cross-episode LLM synthesis | 0.6 (inferred) |
      | ProceduralMemory | Behavioral patterns | 0.6 (inferred) |

      ### Confidence Scoring

      Confidence = weighted sum of:
      - **Extraction method** (50%): verbatim=1.0, extracted=0.9, inferred=0.6
      - **Corroboration** (25%): number of supporting sources
      - **Recency** (15%): how recently confirmed
      - **Verification** (10%): format validation passed

      ### Extraction Methods

      | Method | Base Score | Description |
      |--------|------------|-------------|
      | VERBATIM | 1.0 | Exact quote, immutable |
      | EXTRACTED | 0.9 | Deterministic pattern match (regex, validators) |
      | INFERRED | 0.6 | LLM-derived, uncertain |

      ### Consolidation Flow

      1. Episode stored (ground truth, never modified)
      2. StructuredMemory created immediately (regex: emails, phones, URLs)
      3. Optional LLM enrichment (dates, people, preferences, negations → StructuredMemory)
      4. Background consolidation (N episodes → 1 SemanticMemory)
      5. Procedural synthesis (all SemanticMemories → 1 behavioral profile per user)
      6. Decay applied over time (confidence decreases without confirmation)

      ---

      ## Scientific Claims

      Be careful about claims regarding cognitive science foundations. Engram is **inspired by** cognitive science, not a strict implementation of it.

      ### What we can claim:
      - Multiple memory types are a useful engineering abstraction
      - Ground truth preservation solves a real problem (LLM extraction errors)
      - Confidence tracking distinguishes certain from uncertain
      - Deferred processing reduces cost and latency
      - Some form of forgetting is necessary for relevance and performance

      ### What we should NOT claim:
      - That our architecture mirrors how the brain actually works
      - That episodic/semantic are cleanly separable (they're not — it's a continuum)
      - That consolidation works exactly as we model it (heavily debated)
      - That Ebbinghaus decay is the definitive model of forgetting (it's a simplification)
      - That Atkinson-Shiffrin is current (Baddeley's Working Memory Model superseded it)

      ---

      ## Development Workflow

      ```bash
      # 1. Create branch (never work on main)
      git checkout -b feature/my-feature

      # 2. Make changes, run tests
      uv run pytest tests/ -v --no-cov

      # 3. Format and type check
      uv run ruff check src/engram/ && uv run ruff format src/engram/ && uv run mypy src/engram/

      # 4. Commit, push, create PR
      git push -u origin feature/my-feature
      ```

      ---

      ## Pydantic (Required for All Data Models)

      All data structures MUST use Pydantic. No exceptions.

      ### Model Pattern

      ```python
      from pydantic import BaseModel, ConfigDict, Field

      class MyModel(BaseModel):
          """Always add docstrings."""

          model_config = ConfigDict(extra="forbid")  # Catch typos

          id: str = Field(description="Unique identifier")
          value: float = Field(ge=0.0, le=1.0, description="Bounded value")
          items: list[str] = Field(default_factory=list)
      ```

      ### Rules

      - `ConfigDict(extra="forbid")` on all models (catches field typos)
      - Use `Field()` for validation constraints and descriptions
      - Use `model_dump(mode="json")` for serialization
      - Use `model_validate()` for deserialization
      - Never use `@dataclass`, `TypedDict`, or `NamedTuple`

      ### Settings Pattern

      ```python
      from pydantic import Field
      from pydantic_settings import BaseSettings, SettingsConfigDict

      class Settings(BaseSettings):
          model_config = SettingsConfigDict(env_prefix="ENGRAM_")

          api_key: str | None = Field(default=None)
          debug: bool = Field(default=False)
      ```

      ---

      ## Pydantic AI (Required for All LLM Interactions)

      All LLM calls MUST use Pydantic AI with structured outputs. No raw API calls.

      ### Basic Pattern

      ```python
      from pydantic import BaseModel
      from pydantic_ai import Agent

      class ExtractedFacts(BaseModel):
          """Structured output from LLM extraction."""
          facts: list[str]
          confidence: float
          reasoning: str

      extraction_agent = Agent(
          "openai:gpt-4o-mini",
          result_type=ExtractedFacts,
          system_prompt="Extract factual statements from the conversation.",
      )

      async def extract_facts(text: str) -> ExtractedFacts:
          result = await extraction_agent.run(text)
          return result.data  # Type-safe ExtractedFacts
      ```

      ### Consolidation Agent Example

      ```python
      from pydantic import BaseModel
      from pydantic_ai import Agent

      class ConsolidationResult(BaseModel):
          """Output from memory consolidation."""
          semantic_facts: list[str]
          links: list[tuple[str, str]]  # (memory_id, related_id)
          pruned_ids: list[str]
          confidence: float

      consolidation_agent = Agent(
          "openai:gpt-4o-mini",
          result_type=ConsolidationResult,
          system_prompt="""
          Analyze episodes and extract semantic knowledge.
          Identify relationships between memories.
          Flag weak associations for pruning.
          """,
      )
      ```

      ### Why Pydantic AI?

      - **Type safety**: Responses are validated Pydantic models, not raw dicts
      - **Structured outputs**: LLM returns exactly what you expect
      - **Retries**: Automatic retry on validation failures
      - **Observability**: Built-in logging and tracing

      ---

      ## Key Files

      | File | Purpose |
      |------|---------|
      | `models/` | Pydantic models for all memory types |
      | `storage/` | Qdrant client and collection management |
      | `extraction/` | Pattern matchers and LLM extractors (Pydantic AI agents) |
      | `consolidation/` | Background processing workflows (Pydantic AI agents) |
      | `config.py` | Settings and confidence weights |
      | `api/router.py` | REST API endpoints |
      | `api/schemas.py` | Request/response Pydantic models |
      | `api/auth.py` | Authentication and rate limiting |
      | `context.py` | Memory context manager for SDK usage |

      ---

      ## Memory Types Detail

      Memory types are engineering constructs:
      - **Working, Episodic, Semantic, Procedural** — Inspired by cognitive science
      - **StructuredMemory** — Per-episode LLM extraction bridging raw episodes and cross-episode semantic synthesis

      Be explicit about which are science-inspired and which are engineering additions.

      ---

      ## Scientific Foundations

      Engram is **inspired by** cognitive science research, not a strict implementation of it. Below are the papers we cite and how they inform our design.

      ### Research Reference Table

      | Paper | Year | Key Finding | Engram Implementation |
      |-------|------|-------------|----------------------|
      | [Roediger & Karpicke](https://pmc.ncbi.nlm.nih.gov/articles/PMC5912918/) | 2006 | Retrieval strengthens memory (56% vs 14% retention) | `consolidation_strength`, `consolidation_passes` |
      | [A-MEM](https://arxiv.org/abs/2502.12110) | 2025 | 2x multi-hop reasoning via Zettelkasten linking | `related_ids`, `follow_links` |
      | [Cognitive Workspace](https://arxiv.org/abs/2508.13171) | 2025 | 58.6% memory reuse vs 0% for naive RAG | Hierarchical buffers, working memory |
      | [HaluMem](https://arxiv.org/abs/2511.03506) | 2025 | <56% accuracy without ground truth preservation | Immutable episodes, `verify()` |
      | [Karpicke & Roediger](https://www.sciencedirect.com/science/article/abs/pii/S1364661310002081) | 2008 | Retrieval = rapid consolidation | Retrieval-triggered strengthening |

      ### Testing Effect (Consolidation Strength)

      **What it is**: Memories that are repeatedly involved in retrieval and consolidation become stronger and more stable.

      **Primary Research**:
      > Roediger, H.L. & Karpicke, J.D. (2006). "The Power of Testing Memory: Basic Research and Implications for Educational Practice." *Perspectives on Psychological Science*, 1(3), 181-210.

      **Key experimental results**:
      - After 1 week: Tested group retained **56%**, study-only group retained **14%**
      - Testing produces "rapid consolidation" of memory traces
      - "Repeated remembering strengthens memories much more so than repeated learning"

      **How we implement it**: During consolidation, `strengthen()` is called when existing memories:
      1. Get linked to new memories via semantic similarity
      2. Receive LLM-identified links
      3. Undergo evolution (tag/keyword/context updates)

      Each call increases `consolidation_strength` by 0.1 and increments `consolidation_passes`.

      ### A-MEM (Dynamic Memory Linking)

      **What it is**: Agentic memory architecture using Zettelkasten-style linking for multi-hop reasoning.

      **Primary Research**:
      > "A-MEM: Agentic Memory for LLM Agents" (2025). https://arxiv.org/abs/2502.12110

      **Key results**:
      - **2x improvement** on multi-hop reasoning benchmarks
      - Dynamic linking outperforms static memory retrieval
      - Links enable contextual relevance across domains

      **How we implement it**: `related_ids` field on SemanticMemory and ProceduralMemory stores bidirectional links. During consolidation, `_find_matching_memory()` discovers links via exact, normalized, and substring matching. `follow_links=True` in `recall()` traverses links for multi-hop reasoning.

      ### HaluMem (Ground Truth Preservation)

      **What it is**: Benchmark showing LLM memory systems hallucinate without source preservation.

      **Primary Research**:
      > "HaluMem: Evaluating Hallucinations in Memory Systems of Agents" (2025). https://arxiv.org/abs/2511.03506

      **Key results**:
      - "All systems achieve answer accuracies below **56%**"
      - "Hallucination rate and omission rate remaining high"
      - "Systems suffer omission rates above 50%"

      **How we address it**: Immutable episodic storage preserves ground truth. All derived memories (`StructuredMemory`, `SemanticMemory`) maintain `source_episode_ids` for traceability. `verify()` enables auditing any memory back to its source.

      ### Cognitive Workspace (Hierarchical Buffers)

      **What it is**: Active memory curation using hierarchical buffer management.

      **Primary Research**:
      > "Cognitive Workspace for AI Memory" (2025). https://arxiv.org/abs/2508.13171

      **Key results**:
      - **58.6% memory reuse** vs 0% for naive RAG
      - Active curation outperforms passive retrieval
      - Hierarchical organization improves recall relevance

      **How we implement it**: Working memory → Episodic → StructuredMemory → SemanticMemory → ProceduralMemory hierarchy. Each tier serves different retention and retrieval purposes.

      ### Surprise-Based Importance (Adaptive Compression)

      **What it is**: Novel information receives higher importance scores than redundant content.

      **Primary Research**:
      > Nagy et al. (2025). "Adaptive Compression for Memory-Augmented Language Models." https://arxiv.org/abs/2502.14842

      **Key insight**: Information-theoretic surprise (low similarity to existing memories) indicates novel, valuable content worth retaining.

      **How we implement it**: During episode encoding, `_calculate_surprise()` computes novelty by comparing embeddings to existing memories. Low similarity = high surprise = boosted importance score. Controlled by `surprise_scoring_enabled`, `surprise_weight` (default 0.15), and `surprise_search_limit` settings.

      ### What we DON'T implement

      - **Exact biological mechanisms**: We use cognitive science as inspiration, not blueprint
      - **True context selectivity**: Tomé et al. (2024) describes how engrams become more context-specific via inhibitory plasticity. We don't model this — we track consolidation involvement instead
      - **Retrieval-induced forgetting**: Removed in v0.x due to context mismatch between human lab experiments and AI systems

      ---

      ## Communication

      Be concise and direct. No flattery or excessive praise. Focus on what needs to be done.
    agentsMd: |
      # Engram Agent Guide

      **What is Engram**: Memory you can trust. A memory system for AI applications that preserves ground truth, tracks confidence, and prevents hallucinations.

      **Status**: Beta. 800+ tests. Core APIs, REST endpoints, and workflows fully implemented.

      **Your Role**: Python backend engineer building a memory layer for AI agents. You write production-grade code with comprehensive tests.

      **Design Philosophy**: Ground truth preservation, auditable confidence, deferred consolidation.

      ---

      ## Boundaries

      ### Always Do (No Permission Needed)

      - Write complete, production-grade code (no TODOs, no placeholders)
      - Add tests for all new features (test both success and error cases)
      - Use type hints (mypy strict mode)
      - Follow async/await patterns for all database operations
      - Update README.md when adding user-facing features
      - Add docstrings to public functions
      - **Use Pydantic for ALL data models** — no dataclasses, no TypedDict, no NamedTuple
      - **Use Pydantic AI for ALL LLM interactions** — structured outputs, type-safe responses

      ### Ask First

      - Modifying database models (affects migrations)
      - Changing API contracts (breaking for consumers)
      - Adding new dependencies to pyproject.toml
      - Deleting existing endpoints or models
      - Refactoring core services (storage, extraction, consolidation)

      ### Never Do

      **GitHub Issues**:
      - NEVER close an issue unless ALL acceptance criteria are met
      - If an issue has checkboxes, ALL boxes must be checked before closing
      - If you can't complete all criteria, leave the issue open and comment on what remains

      **Git**:
      - NEVER commit directly to main - always use a feature branch and PR
      - NEVER push directly to main - all changes must go through pull requests
      - NEVER force push to shared branches
      - Do NOT include "Co-Authored-By: Claude" or the "Generated with Claude Code" footer

      **Security**:
      - NEVER commit credentials, API keys, tokens, or passwords
      - Use environment variables (.env is in .gitignore)
      - Pre-commit check: `grep -r "sk-\|sk-ant-\|AIza" src/ tests/ && echo "SECRETS FOUND" || echo "OK"`

      **Code Quality**:
      - Skip tests to make builds pass
      - Disable type checking or linting
      - Leave TODO comments in production code
      - Delete failing tests instead of fixing them

      ---

      ## Commands

      ```bash
      # Setup
      uv sync --extra dev

      # Run tests
      uv run pytest tests/ -v --no-cov

      # Code quality
      uv run ruff check src/engram/
      uv run ruff format src/engram/
      uv run mypy src/engram/

      # Pre-commit
      uv run pre-commit install
      uv run pre-commit run --all-files

      # Start REST API server
      uv run uvicorn engram.api.app:app --port 8000
      ```

      ---

      ## REST API

      All endpoints are prefixed with `/api/v1`. Key endpoints:

      | Endpoint | Method | Description |
      |----------|--------|-------------|
      | `/encode` | POST | Store episode + extract structured data |
      | `/encode/batch` | POST | Bulk import (up to 100 items) |
      | `/recall` | POST | Semantic search across memory types |
      | `/memories/{id}` | GET | Get specific memory |
      | `/memories/{id}` | DELETE | Delete memory (with cascade options) |
      | `/memories/{id}/verify` | GET | Trace memory to source |
      | `/workflows/consolidate` | POST | Episodes → Semantic memories |
      | `/workflows/promote` | POST | Semantic → Procedural |

      See `docs/api.md` for full documentation.

      ---

      ## Key Concepts

      ### Memory Types (5)

      | Type | Purpose | Confidence |
      |------|---------|------------|
      | Working | Current session context (in-memory, not persisted) | N/A |
      | Episode | Immutable ground truth (raw interactions) | N/A (verbatim) |
      | StructuredMemory | Per-episode LLM extraction (entities, summary, negations) | 0.8-0.9 |
      | SemanticMemory | Cross-episode LLM synthesis | 0.6 (inferred) |
      | ProceduralMemory | Behavioral patterns | 0.6 (inferred) |

      ### Confidence Scoring

      Confidence = weighted sum of:
      - **Extraction method** (50%): verbatim=1.0, extracted=0.9, inferred=0.6
      - **Corroboration** (25%): number of supporting sources
      - **Recency** (15%): how recently confirmed
      - **Verification** (10%): format validation passed

      ### Extraction Methods

      | Method | Base Score | Description |
      |--------|------------|-------------|
      | VERBATIM | 1.0 | Exact quote, immutable |
      | EXTRACTED | 0.9 | Deterministic pattern match (regex, validators) |
      | INFERRED | 0.6 | LLM-derived, uncertain |

      ### Consolidation Flow

      1. Episode stored (ground truth, never modified)
      2. StructuredMemory created immediately (regex: emails, phones, URLs)
      3. Optional LLM enrichment (dates, people, preferences, negations → StructuredMemory)
      4. Background consolidation (N episodes → 1 SemanticMemory)
      5. Procedural synthesis (all SemanticMemories → 1 behavioral profile per user)
      6. Decay applied over time (confidence decreases without confirmation)

      ---

      ## Scientific Claims

      Be careful about claims regarding cognitive science foundations. Engram is **inspired by** cognitive science, not a strict implementation of it.

      ### What we can claim:
      - Multiple memory types are a useful engineering abstraction
      - Ground truth preservation solves a real problem (LLM extraction errors)
      - Confidence tracking distinguishes certain from uncertain
      - Deferred processing reduces cost and latency
      - Some form of forgetting is necessary for relevance and performance

      ### What we should NOT claim:
      - That our architecture mirrors how the brain actually works
      - That episodic/semantic are cleanly separable (they're not — it's a continuum)
      - That consolidation works exactly as we model it (heavily debated)
      - That Ebbinghaus decay is the definitive model of forgetting (it's a simplification)
      - That Atkinson-Shiffrin is current (Baddeley's Working Memory Model superseded it)

      ---

      ## Development Workflow

      ```bash
      # 1. Create branch (never work on main)
      git checkout -b feature/my-feature

      # 2. Make changes, run tests
      uv run pytest tests/ -v --no-cov

      # 3. Format and type check
      uv run ruff check src/engram/ && uv run ruff format src/engram/ && uv run mypy src/engram/

      # 4. Commit, push, create PR
      git push -u origin feature/my-feature
      ```

      ---

      ## Pydantic (Required for All Data Models)

      All data structures MUST use Pydantic. No exceptions.

      ### Model Pattern

      ```python
      from pydantic import BaseModel, ConfigDict, Field

      class MyModel(BaseModel):
          """Always add docstrings."""

          model_config = ConfigDict(extra="forbid")  # Catch typos

          id: str = Field(description="Unique identifier")
          value: float = Field(ge=0.0, le=1.0, description="Bounded value")
          items: list[str] = Field(default_factory=list)
      ```

      ### Rules

      - `ConfigDict(extra="forbid")` on all models (catches field typos)
      - Use `Field()` for validation constraints and descriptions
      - Use `model_dump(mode="json")` for serialization
      - Use `model_validate()` for deserialization
      - Never use `@dataclass`, `TypedDict`, or `NamedTuple`

      ### Settings Pattern

      ```python
      from pydantic import Field
      from pydantic_settings import BaseSettings, SettingsConfigDict

      class Settings(BaseSettings):
          model_config = SettingsConfigDict(env_prefix="ENGRAM_")

          api_key: str | None = Field(default=None)
          debug: bool = Field(default=False)
      ```

      ---

      ## Pydantic AI (Required for All LLM Interactions)

      All LLM calls MUST use Pydantic AI with structured outputs. No raw API calls.

      ### Basic Pattern

      ```python
      from pydantic import BaseModel
      from pydantic_ai import Agent

      class ExtractedFacts(BaseModel):
          """Structured output from LLM extraction."""
          facts: list[str]
          confidence: float
          reasoning: str

      extraction_agent = Agent(
          "openai:gpt-4o-mini",
          result_type=ExtractedFacts,
          system_prompt="Extract factual statements from the conversation.",
      )

      async def extract_facts(text: str) -> ExtractedFacts:
          result = await extraction_agent.run(text)
          return result.data  # Type-safe ExtractedFacts
      ```

      ### Consolidation Agent Example

      ```python
      from pydantic import BaseModel
      from pydantic_ai import Agent

      class ConsolidationResult(BaseModel):
          """Output from memory consolidation."""
          semantic_facts: list[str]
          links: list[tuple[str, str]]  # (memory_id, related_id)
          pruned_ids: list[str]
          confidence: float

      consolidation_agent = Agent(
          "openai:gpt-4o-mini",
          result_type=ConsolidationResult,
          system_prompt="""
          Analyze episodes and extract semantic knowledge.
          Identify relationships between memories.
          Flag weak associations for pruning.
          """,
      )
      ```

      ### Why Pydantic AI?

      - **Type safety**: Responses are validated Pydantic models, not raw dicts
      - **Structured outputs**: LLM returns exactly what you expect
      - **Retries**: Automatic retry on validation failures
      - **Observability**: Built-in logging and tracing

      ---

      ## Key Files

      | File | Purpose |
      |------|---------|
      | `models/` | Pydantic models for all memory types |
      | `storage/` | Qdrant client and collection management |
      | `extraction/` | Pattern matchers and LLM extractors (Pydantic AI agents) |
      | `consolidation/` | Background processing workflows (Pydantic AI agents) |
      | `config.py` | Settings and confidence weights |
      | `api/router.py` | REST API endpoints |
      | `api/schemas.py` | Request/response Pydantic models |
      | `api/auth.py` | Authentication and rate limiting |
      | `context.py` | Memory context manager for SDK usage |

      ---

      ## Memory Types Detail

      Memory types are engineering constructs:
      - **Working, Episodic, Semantic, Procedural** — Inspired by cognitive science
      - **StructuredMemory** — Per-episode LLM extraction bridging raw episodes and cross-episode semantic synthesis

      Be explicit about which are science-inspired and which are engineering additions.

      ---

      ## Scientific Foundations

      Engram is **inspired by** cognitive science research, not a strict implementation of it. Below are the papers we cite and how they inform our design.

      ### Research Reference Table

      | Paper | Year | Key Finding | Engram Implementation |
      |-------|------|-------------|----------------------|
      | [Roediger & Karpicke](https://pmc.ncbi.nlm.nih.gov/articles/PMC5912918/) | 2006 | Retrieval strengthens memory (56% vs 14% retention) | `consolidation_strength`, `consolidation_passes` |
      | [A-MEM](https://arxiv.org/abs/2502.12110) | 2025 | 2x multi-hop reasoning via Zettelkasten linking | `related_ids`, `follow_links` |
      | [Cognitive Workspace](https://arxiv.org/abs/2508.13171) | 2025 | 58.6% memory reuse vs 0% for naive RAG | Hierarchical buffers, working memory |
      | [HaluMem](https://arxiv.org/abs/2511.03506) | 2025 | <56% accuracy without ground truth preservation | Immutable episodes, `verify()` |
      | [Karpicke & Roediger](https://www.sciencedirect.com/science/article/abs/pii/S1364661310002081) | 2008 | Retrieval = rapid consolidation | Retrieval-triggered strengthening |

      ### Testing Effect (Consolidation Strength)

      **What it is**: Memories that are repeatedly involved in retrieval and consolidation become stronger and more stable.

      **Primary Research**:
      > Roediger, H.L. & Karpicke, J.D. (2006). "The Power of Testing Memory: Basic Research and Implications for Educational Practice." *Perspectives on Psychological Science*, 1(3), 181-210.

      **Key experimental results**:
      - After 1 week: Tested group retained **56%**, study-only group retained **14%**
      - Testing produces "rapid consolidation" of memory traces
      - "Repeated remembering strengthens memories much more so than repeated learning"

      **How we implement it**: During consolidation, `strengthen()` is called when existing memories:
      1. Get linked to new memories via semantic similarity
      2. Receive LLM-identified links
      3. Undergo evolution (tag/keyword/context updates)

      Each call increases `consolidation_strength` by 0.1 and increments `consolidation_passes`.

      ### A-MEM (Dynamic Memory Linking)

      **What it is**: Agentic memory architecture using Zettelkasten-style linking for multi-hop reasoning.

      **Primary Research**:
      > "A-MEM: Agentic Memory for LLM Agents" (2025). https://arxiv.org/abs/2502.12110

      **Key results**:
      - **2x improvement** on multi-hop reasoning benchmarks
      - Dynamic linking outperforms static memory retrieval
      - Links enable contextual relevance across domains

      **How we implement it**: `related_ids` field on SemanticMemory and ProceduralMemory stores bidirectional links. During consolidation, `_find_matching_memory()` discovers links via exact, normalized, and substring matching. `follow_links=True` in `recall()` traverses links for multi-hop reasoning.

      ### HaluMem (Ground Truth Preservation)

      **What it is**: Benchmark showing LLM memory systems hallucinate without source preservation.

      **Primary Research**:
      > "HaluMem: Evaluating Hallucinations in Memory Systems of Agents" (2025). https://arxiv.org/abs/2511.03506

      **Key results**:
      - "All systems achieve answer accuracies below **56%**"
      - "Hallucination rate and omission rate remaining high"
      - "Systems suffer omission rates above 50%"

      **How we address it**: Immutable episodic storage preserves ground truth. All derived memories (`StructuredMemory`, `SemanticMemory`) maintain `source_episode_ids` for traceability. `verify()` enables auditing any memory back to its source.

      ### Cognitive Workspace (Hierarchical Buffers)

      **What it is**: Active memory curation using hierarchical buffer management.

      **Primary Research**:
      > "Cognitive Workspace for AI Memory" (2025). https://arxiv.org/abs/2508.13171

      **Key results**:
      - **58.6% memory reuse** vs 0% for naive RAG
      - Active curation outperforms passive retrieval
      - Hierarchical organization improves recall relevance

      **How we implement it**: Working memory → Episodic → StructuredMemory → SemanticMemory → ProceduralMemory hierarchy. Each tier serves different retention and retrieval purposes.

      ### Surprise-Based Importance (Adaptive Compression)

      **What it is**: Novel information receives higher importance scores than redundant content.

      **Primary Research**:
      > Nagy et al. (2025). "Adaptive Compression for Memory-Augmented Language Models." https://arxiv.org/abs/2502.14842

      **Key insight**: Information-theoretic surprise (low similarity to existing memories) indicates novel, valuable content worth retaining.

      **How we implement it**: During episode encoding, `_calculate_surprise()` computes novelty by comparing embeddings to existing memories. Low similarity = high surprise = boosted importance score. Controlled by `surprise_scoring_enabled`, `surprise_weight` (default 0.15), and `surprise_search_limit` settings.

      ### What we DON'T implement

      - **Exact biological mechanisms**: We use cognitive science as inspiration, not blueprint
      - **True context selectivity**: Tomé et al. (2024) describes how engrams become more context-specific via inhibitory plasticity. We don't model this — we track consolidation involvement instead
      - **Retrieval-induced forgetting**: Removed in v0.x due to context mismatch between human lab experiments and AI systems

      ---

      ## Communication

      Be concise and direct. No flattery or excessive praise. Focus on what needs to be done.
    readme: >
      <p align="center">
        <img src="assets/engram.jpg" alt="Engram Logo">
      </p>


      # Engram


      **Memory you can trust.**


      A memory system for AI applications that preserves ground truth, tracks
      confidence, and prevents hallucinations.


      ## The Problem


      AI memory systems have an accuracy crisis. Recent benchmarks show:


      > "All systems achieve answer accuracies below 56%, with hallucination
      rate and omission rate remaining high."

      >

      > — [HaluMem: Hallucinations in LLM Memory
      Systems](https://arxiv.org/html/2511.03506)


      The fundamental issue: once source data is lost, errors cannot be
      corrected.


      ## The Solution


      Engram preserves ground truth and tracks confidence:


      1. **Store first, derive later** — Raw conversations stored verbatim. LLM
      extraction happens in background where errors can be caught.

      2. **Track confidence** — Every memory carries a composite score:
      extraction method + corroboration + recency + verification.

      3. **Verify on retrieval** — Applications filter by confidence.
      High-stakes queries use only trusted memories.

      4. **Enable recovery** — Derived memories trace to sources. Errors can be
      corrected by re-deriving.


      ## Quick Start


      ### Installation


      ```bash

      # Clone and install

      git clone https://github.com/ashita-ai/engram.git

      cd engram

      uv sync --extra dev


      # Start Qdrant (vector database)

      docker run -p 6333:6333 qdrant/qdrant

      ```


      ### Python SDK


      ```python

      from engram.service import EngramService


      async with EngramService.create() as engram:
          # Store interaction (immediate, preserves ground truth)
          result = await engram.encode(
              content="My email is john@example.com",
              role="user",
              user_id="user_123",
          )
          print(f"Episode: {result.episode.id}")
          print(f"Emails extracted: {result.structured.emails}")  # ["john@example.com"]

          # Retrieve with confidence filtering
          memories = await engram.recall(
              query="What's the user's email?",
              user_id="user_123",
              min_confidence=0.7,
          )

          # Verify any memory back to source
          verified = await engram.verify(memories[0].memory_id, user_id="user_123")
          print(verified.explanation)
      ```


      ### REST API


      ```bash

      # Start the server

      uv run uvicorn engram.api.app:app --port 8000


      # Encode a memory

      curl -X POST http://localhost:8000/api/v1/encode \
        -H "Content-Type: application/json" \
        -d '{"content": "My email is john@example.com", "role": "user", "user_id": "user_123"}'

      # Recall memories

      curl -X POST http://localhost:8000/api/v1/recall \
        -H "Content-Type: application/json" \
        -d '{"query": "email", "user_id": "user_123"}'

      # Batch encode (bulk import)

      curl -X POST http://localhost:8000/api/v1/encode/batch \
        -H "Content-Type: application/json" \
        -d '{
          "user_id": "user_123",
          "items": [
            {"content": "Message 1", "role": "user"},
            {"content": "Response 1", "role": "assistant"}
          ]
        }'
      ```


      ## Memory Types


      | Type | Confidence | Purpose |

      |------|------------|---------|

      | **Working** | N/A | Current session context (in-memory, volatile) |

      | **Episodic** | Highest | Ground truth, verbatim storage, immutable |

      | **Structured** | High | Per-episode extraction (emails, phones, URLs,
      negations) |

      | **Semantic** | Variable | Cross-episode knowledge synthesis
      (LLM-derived) |

      | **Procedural** | Variable | Behavioral patterns and preferences |


      ### Memory Flow


      ```

      Episode (raw, immutable)
          │
          ├──→ Structured (per-episode: emails, phones, negations)
          │
          └──→ Semantic (LLM consolidation: N episodes → 1 summary)
                    │
                    └──→ Procedural (behavioral synthesis)
      ```


      ## REST API Reference


      ### Core Endpoints


      | Method | Endpoint | Description |

      |--------|----------|-------------|

      | `POST` | `/encode` | Store a memory and extract facts |

      | `POST` | `/encode/batch` | Bulk import multiple memories |

      | `POST` | `/recall` | Semantic search across all memory types |

      | `GET` | `/memories/{id}` | Get a specific memory by ID |

      | `GET` | `/memories` | List memories with filters |

      | `DELETE` | `/memories/{id}` | Delete a memory (with cascade options) |

      | `PATCH` | `/memories/{id}` | Update memory content/metadata |

      | `GET` | `/memories/{id}/sources` | Trace memory to source episodes |

      | `GET` | `/memories/{id}/verify` | Verify memory with explanation |

      | `GET` | `/memories/{id}/provenance` | Full derivation chain |


      ### Workflow Endpoints


      | Method | Endpoint | Description |

      |--------|----------|-------------|

      | `POST` | `/workflows/consolidate` | Episodes → Semantic memories |

      | `POST` | `/workflows/decay` | Apply confidence decay |

      | `POST` | `/workflows/promote` | Semantic → Procedural synthesis |

      | `POST` | `/workflows/structure` | LLM extraction for single episode |

      | `POST` | `/workflows/structure/batch` | LLM extraction for multiple
      episodes |


      ### Additional Features


      | Method | Endpoint | Description |

      |--------|----------|-------------|

      | `POST` | `/memories/{id}/links` | Create memory links |

      | `GET` | `/memories/{id}/links` | List memory links |

      | `DELETE` | `/memories/{id}/links/{target}` | Remove a link |

      | `POST` | `/conflicts/detect` | Detect contradictions |

      | `GET` | `/conflicts` | List detected conflicts |

      | `POST` | `/webhooks` | Register event webhooks |

      | `GET` | `/memories/{id}/history` | Memory change history |

      | `DELETE` | `/users/{user_id}/memories` | GDPR erasure |


      ### Session Endpoints


      | Method | Endpoint | Description |

      |--------|----------|-------------|

      | `GET` | `/sessions` | List sessions for a user |

      | `GET` | `/sessions/{session_id}` | Get session details with episodes |

      | `DELETE` | `/sessions/{session_id}` | Delete session (with cascade
      options) |


      ## Confidence Scoring


      Confidence is a composite score:


      | Factor | Weight | Description |

      |--------|--------|-------------|

      | Extraction method | 50% | verbatim=1.0, regex=0.9, LLM=0.6 |

      | Corroboration | 25% | Number of supporting sources |

      | Recency | 15% | How recently confirmed |

      | Verification | 10% | Format validation passed |


      Every score is auditable: *"0.73 because: extracted (0.9 base), 3 sources,
      confirmed 2 months ago."*


      ## Configuration


      Environment variables (prefix: `ENGRAM_`):


      | Variable | Default | Description |

      |----------|---------|-------------|

      | `ENV` | `development` | Environment: `development`, `production`, or
      `test` |

      | `QDRANT_URL` | `http://localhost:6333` | Qdrant connection |

      | `EMBEDDING_PROVIDER` | `fastembed` | Embedding backend |

      | `AUTH_ENABLED` | auto | Enable Bearer token auth (auto: true in
      production) |

      | `AUTH_SECRET_KEY` | - | Secret key for auth (required in production) |

      | `RATE_LIMIT_ENABLED` | `false` | Enable rate limiting |

      | `BATCH_ENCODE_MAX_ITEMS` | `100` | Max batch size |


      **Security Notes:**

      - In production (`ENGRAM_ENV=production`), auth is enabled by default

      - Using the default secret key in production will raise an error

      - Generate a secret key: `python -c "import secrets;
      print(secrets.token_hex(32))"`


      See [docs/development.md](docs/development.md) for full configuration
      reference.


      ## Development


      ```bash

      # Run tests

      uv run pytest tests/ -v --no-cov


      # Code quality

      uv run ruff check src/engram/

      uv run mypy src/engram/


      # Pre-commit hooks

      uv run pre-commit install

      uv run pre-commit run --all-files

      ```


      ## Claude Code Integration


      Engram provides an MCP server for direct integration with Claude Code:


      ```json

      {
        "mcpServers": {
          "engram": {
            "command": "uv",
            "args": ["run", "--directory", "/path/to/engram", "--extra", "mcp", "python", "-m", "engram.mcp"]
          }
        }
      }

      ```


      This exposes four tools: `engram_encode`, `engram_recall`,
      `engram_verify`, and `engram_stats`.


      See [docs/mcp.md](docs/mcp.md) for full setup instructions.


      ## Documentation


      - [Architecture](docs/architecture.md) — Memory types, data flow, storage
      design

      - [Development Guide](docs/development.md) — Setup, configuration,
      workflow

      - [API Reference](docs/api.md) — Detailed endpoint documentation

      - [MCP Integration](docs/mcp.md) — Claude Code and MCP client setup


      ## Status


      Beta. Core functionality complete with comprehensive test coverage (800+
      tests).


      ## License


      MIT
constraints:
  - type: technical
    description: Must support uv as primary Python package manager. Must handle
      large repositories efficiently (PHP repos specifically can be very large).
      Should detect pyproject.toml, package.json/tsconfig.json, composer.json,
      and go.mod respectively.
  - type: business
    description: Must support uv as primary Python package manager. Must handle
      large repositories efficiently (PHP repos specifically can be very large).
      Should detect pyproject.toml, package.json/tsconfig.json, composer.json,
      and go.mod respectively.
integrations: []
phases:
  - id: phase-research
    name: Research
    description: Analyze requirements and codebase patterns
    tasks:
      - id: task-research-requirements
        type: research
        description: Analyze epic requirements and identify implementation approach
        agentType: researcher
        agentModel: haiku
        files: []
        acceptanceCriteria:
          - Requirements documented
          - Approach identified
        constraints: []
        dependsOn: []
        estimatedTokens: 10000
        estimatedMinutes: 5
      - id: task-research-codebase
        type: research
        description: Identify relevant existing patterns and files
        agentType: researcher
        agentModel: haiku
        files:
          - .env.example
        acceptanceCriteria:
          - Relevant files identified
          - Patterns documented
        constraints: []
        dependsOn: []
        estimatedTokens: 15000
        estimatedMinutes: 8
    parallel: true
    dependencies: []
    checkpointAfter: true
    checkpointReason: Validate research findings before architecture
    estimatedDurationMinutes: 15
  - id: phase-architecture
    name: Architecture
    description: Design technical approach and component structure
    tasks:
      - id: task-design-architecture
        type: design
        description: Design component structure and data flow
        agentType: system-architect
        agentModel: sonnet
        files: []
        acceptanceCriteria:
          - Architecture documented
          - Data flow defined
        constraints: []
        dependsOn:
          - task-research-requirements
          - task-research-codebase
        estimatedTokens: 20000
        estimatedMinutes: 10
    parallel: false
    dependencies:
      - phase-research
    checkpointAfter: true
    checkpointReason: Validate architecture before implementation
    estimatedDurationMinutes: 10
  - id: phase-implementation
    name: Implementation
    description: Build the POC
    tasks:
      - id: task-implement-core
        type: implement
        description: Implement core functionality
        agentType: coder
        agentModel: sonnet
        files: []
        acceptanceCriteria:
          - "[ ] `hasTests: true` when `tests/test_*.py` files exist"
          - "[ ] `hasLinting: true` when `[tool.ruff]` or similar configured"
          - "[ ] `dependencies` populated from pyproject.toml"
        constraints:
          - Must support uv as primary Python package manager. Must handle large
            repositories efficiently (PHP repos specifically can be very large).
            Should detect pyproject.toml, package.json/tsconfig.json,
            composer.json, and go.mod respectively.
        dependsOn:
          - task-design-architecture
        estimatedTokens: 50000
        estimatedMinutes: 30
    parallel: false
    dependencies:
      - phase-architecture
    checkpointAfter: true
    checkpointReason: Review implementation before testing
    estimatedDurationMinutes: 30
  - id: phase-testing
    name: Testing
    description: Write and run tests
    tasks:
      - id: task-write-tests
        type: test
        description: Write unit and integration tests
        agentType: tester
        agentModel: sonnet
        files: []
        acceptanceCriteria:
          - Tests written
          - Coverage > 80%
        constraints: []
        dependsOn:
          - task-implement-core
        estimatedTokens: 30000
        estimatedMinutes: 20
    parallel: false
    dependencies:
      - phase-implementation
    checkpointAfter: false
    estimatedDurationMinutes: 20
  - id: phase-review
    name: Review
    description: Code review and final validation
    tasks:
      - id: task-code-review
        type: review
        description: Review code quality, security, and best practices
        agentType: reviewer
        agentModel: sonnet
        files: []
        acceptanceCriteria:
          - No critical issues
          - Best practices followed
        constraints: []
        dependsOn:
          - task-write-tests
        estimatedTokens: 15000
        estimatedMinutes: 10
    parallel: false
    dependencies:
      - phase-testing
    checkpointAfter: true
    checkpointReason: Final review before delivery
    estimatedDurationMinutes: 10
checkpoints:
  - id: checkpoint-post-research
    type: post-research
    phase: phase-research
    required: true
    autoApprove: false
    description: Review research findings before proceeding to architecture
    artifactTypes:
      - research-summary
      - relevant-files-list
    questionsToAsk:
      - Are the research findings accurate?
      - Should we adjust the scope based on findings?
  - id: checkpoint-post-architecture
    type: post-architecture
    phase: phase-architecture
    required: true
    autoApprove: false
    description: Validate architecture before implementation
    artifactTypes:
      - architecture-diagram
      - tech-decisions
    questionsToAsk:
      - Does this architecture fit the existing codebase?
      - Are there any concerns with this approach?
  - id: checkpoint-post-implementation
    type: post-implementation
    phase: phase-implementation
    required: true
    autoApprove: false
    description: Review implementation before testing
    artifactTypes:
      - code-diff
      - implementation-summary
    questionsToAsk:
      - Does the implementation meet requirements?
      - Any obvious issues to fix?
  - id: checkpoint-pre-delivery
    type: pre-delivery
    phase: phase-review
    required: true
    autoApprove: false
    description: Final approval before delivery
    artifactTypes:
      - test-results
      - review-summary
      - delivery-package
    questionsToAsk:
      - Is the POC ready for delivery?
      - Any known issues to document?
acceptanceCriteria:
  - id: ac-1
    description: "[ ] `hasTests: true` when `tests/test_*.py` files exist"
    given: The POC is implemented
    when: The user interacts with the feature
    then: "[ ] `hasTests: true` when `tests/test_*.py` files exist"
    priority: must-have
    testable: true
    automatable: true
  - id: ac-2
    description: "[ ] `hasLinting: true` when `[tool.ruff]` or similar configured"
    given: The POC is implemented
    when: The user interacts with the feature
    then: "[ ] `hasLinting: true` when `[tool.ruff]` or similar configured"
    priority: should-have
    testable: true
    automatable: true
  - id: ac-3
    description: "[ ] `dependencies` populated from pyproject.toml"
    given: The POC is implemented
    when: The user interacts with the feature
    then: "[ ] `dependencies` populated from pyproject.toml"
    priority: should-have
    testable: true
    automatable: true
  - id: ac-4
    description: "[ ] `frameworks` detects FastAPI, Pydantic, etc."
    given: The POC is implemented
    when: The user interacts with the feature
    then: "[ ] `frameworks` detects FastAPI, Pydantic, etc."
    priority: should-have
    testable: true
    automatable: true
  - id: ac-5
    description: "[ ] Convention examples use Python patterns (`test_*.py`, `__init__.py`)"
    given: The POC is implemented
    when: The user interacts with the feature
    then: "[ ] Convention examples use Python patterns (`test_*.py`, `__init__.py`)"
    priority: should-have
    testable: true
    automatable: true
  - id: ac-6
    description: "[ ] Test coverage percentage parsed from coverage reports if available"
    given: The POC is implemented
    when: The user interacts with the feature
    then: "[ ] Test coverage percentage parsed from coverage reports if available"
    priority: should-have
    testable: true
    automatable: true
  - id: ac-7
    description: "[ ] Works for both `pyproject.toml` and legacy `setup.py` projects"
    given: The POC is implemented
    when: The user interacts with the feature
    then: "[ ] Works for both `pyproject.toml` and legacy `setup.py` projects"
    priority: should-have
    testable: true
    automatable: true
  - id: ac-8
    description: "Project with pyproject.toml + [tool.pytest] → hasTests: true"
    given: The POC is implemented
    when: The user interacts with the feature
    then: "Project with pyproject.toml + [tool.pytest] → hasTests: true"
    priority: should-have
    testable: true
    automatable: true
  - id: ac-9
    description: "Project with pyproject.toml + [tool.ruff] → hasLinting: true"
    given: The POC is implemented
    when: The user interacts with the feature
    then: "Project with pyproject.toml + [tool.ruff] → hasLinting: true"
    priority: should-have
    testable: true
    automatable: true
  - id: ac-10
    description: Project with pyproject.toml + [tool.mypy] → no "Type Safety" risk
    given: The POC is implemented
    when: The user interacts with the feature
    then: Project with pyproject.toml + [tool.mypy] → no "Type Safety" risk
    priority: should-have
    testable: true
    automatable: true
  - id: ac-11
    description: 'Project with FastAPI in dependencies → frameworks: ["FastAPI"]'
    given: The POC is implemented
    when: The user interacts with the feature
    then: 'Project with FastAPI in dependencies → frameworks: ["FastAPI"]'
    priority: should-have
    testable: true
    automatable: true
  - id: ac-12
    description: Project with tests/test_*.py → convention examples show Python patterns
    given: The POC is implemented
    when: The user interacts with the feature
    then: Project with tests/test_*.py → convention examples show Python patterns
    priority: should-have
    testable: true
    automatable: true
testStrategy:
  unitTests: true
  integrationTests: true
  e2eTests: false
  coverageTarget: 80
  notes:
    - Focus on critical path coverage
    - Mock external dependencies
estimatedCost:
  totalTokens: 140000
  estimatedCostUSD: 0.95
  breakdown:
    phase-research: 0.05
    phase-architecture: 0.1
    phase-implementation: 0.5
    phase-testing: 0.2
    phase-review: 0.1
  confidence: medium
estimatedDuration:
  totalMinutes: 85
  breakdown:
    phase-research: 15
    phase-architecture: 10
    phase-implementation: 30
    phase-testing: 20
    phase-review: 10
  parallelizable: 25
  confidence: medium
risks:
  - id: risk-user-identified
    description: Variety of manifest file formats across languages. Large PHP
      monorepos may have performance issues. Edge cases with polyglot repos
      containing multiple language manifests.
    likelihood: medium
    impact: medium
    mitigation: Monitor during implementation
  - id: risk-scope-creep
    description: Scope may expand during implementation
    likelihood: medium
    impact: medium
    mitigation: Use checkpoints to validate scope at each phase
readinessScore: 82
readinessIssues: []
createdAt: 2026-01-25T00:32:04.100Z
updatedAt: 2026-01-25T00:32:04.100Z
